# Before starting the inference, we need to preprocess the input data.
# Assuming our input data is of shape [h, w, c], the following parameters are its preprocessing parameters.
preprocess:
  # Resize the image to [1, 320, 320].
  - LetterBox:
      width: 320
      height: 320
      scalar: [ 114,114,114 ]
  # Perform color channel transformation, converting RGB colors to BGR.
  - BGRToRGB:
  # Perform normalization operation.
  - Normalize:
      mean: &normalize_mean [ 0.5, 0.5, 0.5 ]
      std: &normalize_std [ 0.5, 0.5, 0.5 ]
  # The input to the ONNX model is in NCHW format, and we need to change the memory layout of the data from NHWC to NCHW.
  - HWCToCHW:

# After preprocessing, we obtain an input vector of [1, 3, 224, 224], and now we need to perform inference.
# The following parameters are the configuration settings for the RKNN backend:
rknn_export:
  - Config:
      mean_values: *normalize_mean
      std_values: *normalize_std
      target_platform: "RK3568"
  #      target_platform: "RK3588"
  - LoadONNX:
      inputs: [ "input.1" ]
      input_size_list: [ [ 1,3,640,640 ] ]
      input_initial_val: null
      outputs: null
  - Build:
      do_quantization: true
      dataset: PADDLE_DETECTION_Model/picture_lists.txt
      rknn_batch_size: null


postprocess: